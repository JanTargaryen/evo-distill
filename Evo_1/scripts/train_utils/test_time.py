import sys
import os
import json
import time
import torch
import numpy as np
from types import SimpleNamespace
from PIL import Image

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.dirname(__file__), ".."))))
from scripts.Evo1 import EVO1

CKPT_DIR = "/mnt/data_ssd/zhoufang/code/Evo-1/Evo_1/checkpoints/checkpoints_reflow_offline/checkpoint_epoch_30" 
DEVICE = "cuda"
NUM_WARMUP = 5    
NUM_REPEAT = 20   

class Profiler:
    def __init__(self, name):
        self.name = name
        self.times = []
        self.start_event = torch.cuda.Event(enable_timing=True)
        self.end_event = torch.cuda.Event(enable_timing=True)

    def start(self):
        torch.cuda.synchronize()
        self.start_event.record()

    def end(self):
        self.end_event.record()
        torch.cuda.synchronize()
        elapsed = self.start_event.elapsed_time(self.end_event) # æ¯«ç§’
        self.times.append(elapsed)

    def report(self):
        avg_time = np.mean(self.times)
        std_time = np.std(self.times)
        min_time = np.min(self.times)
        max_time = np.max(self.times)
        print(f"â±ï¸  [{self.name}]")
        print(f"    Avg: {avg_time:.2f} ms Â± {std_time:.2f}")
        print(f"    Min: {min_time:.2f} ms | Max: {max_time:.2f} ms")
        return avg_time

def load_model(ckpt_dir):
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {ckpt_dir} ...")
    config_path = os.path.join(ckpt_dir, "config.json")
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶: {config_path}")
        
    with open(config_path, "r") as f:
        config = json.load(f)

    # å¼ºåˆ¶è®¾ç½®æ¨ç†å‚æ•°ï¼Œä¸ server ä¿æŒä¸€è‡´
    config["finetune_vlm"] = False
    config["finetune_action_head"] = False
    # Flow Matching çš„æ¨ç†æ­¥æ•°ï¼Œé€šå¸¸å½±å“ Action Head çš„è€—æ—¶
    config["num_inference_timesteps"] = config.get("num_inference_timesteps", 32) 

    model = EVO1(config).eval()
    
    ckpt_path = os.path.join(ckpt_dir, "mp_rank_00_model_states.pt")
    checkpoint = torch.load(ckpt_path, map_location="cpu")
    model.load_state_dict(checkpoint["module"], strict=True)
    model = model.to(DEVICE)
    
    # æ‰“å°å…³é”®å‚æ•°
    print(f"æ¨¡å‹åŠ è½½å®Œæˆã€‚")
    print(f" - Horizon: {model.horizon}")
    print(f" - Inference Timesteps: {config['num_inference_timesteps']}")
    
    return model

def generate_dummy_inputs(device):
    """ç”Ÿæˆç¬¦åˆæ¨¡å‹è¾“å…¥çš„å‡æ•°æ®"""
    # æ¨¡æ‹Ÿ 3 å¼  448x448 çš„å›¾åƒ (RGB)
    dummy_images = []
    for _ in range(3):
        img_array = np.random.randint(0, 255, (448, 448, 3), dtype=np.uint8)
        dummy_images.append(Image.fromarray(img_array))
    
    # æ¨¡æ‹Ÿ Prompt
    prompt = "Pick up the red cube."
    
    # æ¨¡æ‹Ÿ State (å‡è®¾æ˜¯å½’ä¸€åŒ–åçš„çŠ¶æ€)
    # é€šå¸¸ state_dim æ˜¯ 24 (åŒ…å« padding)
    state = torch.randn(1, 24, device=device, dtype=torch.float32)
    
    # æ¨¡æ‹Ÿ Masks
    image_mask = torch.tensor([1, 1, 0], dtype=torch.int32, device=device) # å‡è®¾ç¬¬ä¸‰å¼ å›¾æ— æ•ˆ
    action_mask = torch.tensor([[1]*7 + [0]*17], dtype=torch.int32, device=device)
    
    return dummy_images, prompt, state, image_mask, action_mask

def run_profile(model):
    images, prompt, state, image_mask, action_mask = generate_dummy_inputs(DEVICE)
    
    # å®šä¹‰è®¡æ—¶å™¨
    prof_vlm = Profiler("VLM Embedding (InternVL3)")
    prof_act = Profiler("Action Head (Flow Matching)")
    prof_total = Profiler("End-to-End Inference")

    print(f"\nå¼€å§‹é¢„çƒ­ ({NUM_WARMUP} æ¬¡) ...")
    with torch.no_grad(), torch.amp.autocast(device_type="cuda", dtype=torch.bfloat16):
        for _ in range(NUM_WARMUP):
            # è¿è¡Œä¸€æ¬¡å®Œæ•´çš„æ¨ç†æµç¨‹
            fused_tokens = model.get_vl_embeddings(images, image_mask, prompt)
            _ = model.predict_action(fused_tokens, state, action_mask=action_mask)

    print(f"å¼€å§‹æµ‹è¯• ({NUM_REPEAT} æ¬¡) ...")
    with torch.no_grad(), torch.amp.autocast(device_type="cuda", dtype=torch.bfloat16):
        for i in range(NUM_REPEAT):
            torch.cuda.synchronize()
            
            # --- æ€»æ—¶é—´å¼€å§‹ ---
            prof_total.start()
            
            # 1. æµ‹è¯• VLM éƒ¨åˆ†
            prof_vlm.start()
            fused_tokens = model.get_vl_embeddings(
                images=images,
                image_mask=image_mask,
                prompt=prompt,
                return_cls_only=False
            )
            prof_vlm.end()
            
            # 2. æµ‹è¯• Action Head éƒ¨åˆ†
            # æ³¨æ„ï¼šè¿™é‡ŒåŒ…å«äº† Flow Matching çš„å¾ªç¯å»å™ªæ­¥éª¤
            prof_act.start()
            action = model.predict_action(
                fused_tokens, 
                state, 
                action_mask=action_mask
            )
            prof_act.end()
            
            # --- æ€»æ—¶é—´ç»“æŸ ---
            prof_total.end()
            
            print(f"\rè¿›åº¦: {i+1}/{NUM_REPEAT}", end="")
    
    print("\n\n" + "="*40)
    print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Š (Device: {DEVICE})")
    print("="*40)
    
    t_vlm = prof_vlm.report()
    t_act = prof_act.report()
    t_total = prof_total.report()
    
    print("-" * 40)
    print(f"VLM å æ¯”: {t_vlm/t_total*100:.1f}%")
    print(f"Action Head å æ¯”: {t_act/t_total*100:.1f}%")
    print("="*40)

if __name__ == "__main__":
    try:
        model = load_model(CKPT_DIR)
        run_profile(model)
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ CKPT_DIR è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠæ˜¯å¦å®‰è£…äº†å¿…è¦çš„ä¾èµ–åº“ã€‚")